import json
import requests
from typing import Optional, Dict, Any, List, Tuple
import logging
import re
import google.generativeai as genai # å¯¼å…¥Gemini SDK
import os # ç”¨äºè®¾ç½®ä»£ç†ç¯å¢ƒå˜é‡
from google.api_core import exceptions as google_api_exceptions # å¯¼å…¥Google APIæ ¸å¿ƒå¼‚å¸¸

# æ—¥å¿—é…ç½®
logger = logging.getLogger('ai_analysis_service')

# OpenAI APIé…ç½®ï¼ˆä»…ä½œä¸ºå¸¸é‡ï¼‰
OPENAI_API_URL = "https://api.openai.com/v1/chat/completions"
OPENAI_MODEL = 'gpt-3.5-turbo'

# ç»“æ„åŒ–æç¤ºè¯æ¨¡æ¿
STOCK_ANALYSIS_PROMPT = """
ä½ æ˜¯ä¸€ä½èµ„æ·±çš„è‚¡ç¥¨åˆ†æå¸ˆï¼Œè¯·åŸºäºæä¾›çš„è‚¡ç¥¨ä¿¡æ¯è¿›è¡Œä¸“ä¸šåˆ†æã€‚

è‚¡ç¥¨ä¿¡æ¯ï¼š
- è‚¡ç¥¨ä»£ç ï¼š{stock_code}
- è‚¡ç¥¨åç§°ï¼š{stock_name}
- å½“å‰ä»·æ ¼ï¼š{current_price}
- ä»·æ ¼å˜åŠ¨ï¼š{price_change_info}

**æŠ€æœ¯é¢æ•°æ®å‚è€ƒï¼š**
{technical_data_section}

**åŸºæœ¬é¢æ•°æ®å‚è€ƒ (æ¥è‡ªAkShare)ï¼š**
{fundamental_data_section}

**é‡è¦åˆ†ææŒ‡å¯¼ï¼š**
å¦‚æœä¸Šè¿°åŸºæœ¬é¢æ•°æ®ç¼ºå¤±æˆ–ä¸å®Œæ•´ï¼Œè¯·ä½ ä¸»åŠ¨è¿ç”¨ä»¥ä¸‹æ–¹æ³•è¿›è¡Œåˆ†æï¼š
1. **åˆ©ç”¨çŸ¥è¯†åº“ä¿¡æ¯**ï¼šåŸºäºä½ å¯¹è¯¥å…¬å¸/è¡Œä¸šçš„äº†è§£ï¼Œæä¾›å¸‚ç›ˆç‡ã€å¸‚å‡€ç‡ã€ROEç­‰å…³é”®æŒ‡æ ‡çš„å¤§è‡´èŒƒå›´å’Œè¡Œä¸šå¯¹æ¯”
2. **è¡Œä¸šåˆ†ææ³•**ï¼šç»“åˆè¯¥å…¬å¸æ‰€å±è¡Œä¸šçš„å¹³å‡ä¼°å€¼æ°´å¹³å’Œå‘å±•è¶‹åŠ¿è¿›è¡Œåˆ†æ
3. **å†å²æ•°æ®æ¨ç†**ï¼šåŸºäºè¯¥å…¬å¸å†å²è¡¨ç°å’Œå‘å±•é˜¶æ®µï¼Œæ¨æµ‹å½“å‰å¯èƒ½çš„è´¢åŠ¡çŠ¶å†µ
4. **å¸‚åœºå¯¹æ¯”æ³•**ï¼šä¸åŒè¡Œä¸šç±»ä¼¼è§„æ¨¡å…¬å¸è¿›è¡Œå¯¹æ¯”åˆ†æ
5. **æœ€æ–°å¸‚åœºä¿¡æ¯**ï¼šç»“åˆä½ æ‰€äº†è§£çš„æœ€æ–°è¡Œä¸šåŠ¨æ€ã€æ”¿ç­–å½±å“ç­‰è¿›è¡Œç»¼åˆåˆ¤æ–­

**ç‰¹åˆ«è¦æ±‚ï¼š**
- æ³¨æ„: è‚¡ç¥¨ä»£ç å’Œè‚¡ç¥¨åç§°æ˜¯é…å¯¹çš„ï¼Œè¯·ç¡®ä¿ä½ åŸºäºæ­£ç¡®çš„å…¬å¸è¿›è¡Œåˆ†æ
- åœ¨æŠ€æœ¯é¢åˆ†æä¸­æ˜ç¡®è¯´æ˜ä½ è¿ç”¨äº†å“ªäº›æŠ€æœ¯åˆ†ææ–¹æ³•å’Œæ¨ç†ä¾æ®
- åœ¨åŸºæœ¬é¢åˆ†æä¸­æ˜ç¡®è¯´æ˜ä½ é‡‡ç”¨äº†å“ªç§åˆ†ææ–¹æ³•
- æä¾›åŸºäºè¡Œä¸šç»éªŒå’Œå¸‚åœºå¸¸è¯†çš„åˆç†ä¼°å€¼åˆ¤æ–­
- æŒ‡å‡ºè¯¥è‚¡ç¥¨åœ¨å½“å‰å¸‚åœºç¯å¢ƒä¸‹çš„æŠ•èµ„ä»·å€¼å’Œé£é™©ç‚¹
- å³ä½¿æ²¡æœ‰å®æ—¶æ•°æ®ï¼Œä¹Ÿè¦ç»™å‡ºä¸“ä¸šçš„æŠ€æœ¯é¢å’ŒåŸºæœ¬é¢åˆ†ææ„è§

è¯·æä¾›ç»“æ„åŒ–çš„åˆ†æç»“æœï¼Œå¿…é¡»æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼š

{{
    "overall_score": æ•°å­— (0-100çš„è¯„åˆ†),
    "recommendation": "å­—ç¬¦ä¸² (Buy/Sell/Hold/Monitor ä¹‹ä¸€)",
    "technical_summary": "å­—ç¬¦ä¸² (æŠ€æœ¯é¢åˆ†ææ‘˜è¦ï¼Œè¯·ä¸»åŠ¨è¿ç”¨æŠ€æœ¯åˆ†æçŸ¥è¯†è¿›è¡Œä¸“ä¸šåˆ†æ)",
    "fundamental_summary": "å­—ç¬¦ä¸² (åŸºæœ¬é¢åˆ†ææ‘˜è¦ï¼Œå½“æ•°æ®ç¼ºå¤±æ—¶è¯·ä¸»åŠ¨è¿ç”¨ä¸Šè¿°åˆ†ææ–¹æ³•)",
    "sentiment_summary": "å­—ç¬¦ä¸² (å¸‚åœºæƒ…ç»ªåˆ†æï¼Œå¯åŸºäºé€šç”¨å¸‚åœºè®¤çŸ¥)",
    "key_reasons": ["ç†ç”±1", "ç†ç”±2", "ç†ç”±3"],
    "confidence_level": "å­—ç¬¦ä¸² (High/Medium/Low ä¹‹ä¸€)"
}}

åˆ†æè¦æ±‚ï¼š
1. overall_score: ç»¼åˆè¯„åˆ†ï¼Œè€ƒè™‘æŠ€æœ¯é¢ã€åŸºæœ¬é¢ã€å¸‚åœºæƒ…ç»ª
2. recommendation: åŸºäºå½“å‰ä¿¡æ¯ç»™å‡ºæ˜ç¡®å»ºè®®
3. technical_summary: **å³ä½¿ç¼ºå°‘å®æ—¶æŠ€æœ¯æ•°æ®ï¼Œä¹Ÿè¦åŸºäºè‚¡ç¥¨å†å²èµ°åŠ¿å’ŒæŠ€æœ¯åˆ†æçŸ¥è¯†æä¾›ä¸“ä¸šçš„æŠ€æœ¯é¢åˆ†æ**
4. fundamental_summary: **å³ä½¿ç¼ºå°‘å®æ—¶æ•°æ®ï¼Œä¹Ÿè¦åŸºäºè¡Œä¸šçŸ¥è¯†å’Œå¸‚åœºç»éªŒæä¾›ä¸“ä¸šçš„åŸºæœ¬é¢åˆ†æ**
5. sentiment_summary: åŸºäºå¸‚åœºæƒ…ç»ªå’ŒæŠ•èµ„è€…å¿ƒç†åˆ†æ
6. key_reasons: æä¾›3-5ä¸ªæ”¯æŒæ¨èå†³ç­–çš„å…³é”®ç†ç”±
7. confidence_level: è¯„ä¼°åˆ†æç½®ä¿¡åº¦ï¼ˆæ•°æ®ç¼ºå¤±æ—¶å¯è®¾ä¸ºMediumæˆ–Lowï¼‰

è¯·ç¡®ä¿è¾“å‡ºä¸ºæœ‰æ•ˆçš„JSONæ ¼å¼ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—ã€‚
"""

def _clean_markdown_json(content: str) -> str:
    """
    æ¸…ç†Markdownä»£ç å—æ ¼å¼ï¼Œæå–çº¯JSONå†…å®¹
    
    å‚æ•°:
    content (str): å¯èƒ½åŒ…å«Markdownæ ¼å¼çš„å†…å®¹
    
    è¿”å›:
    str: æ¸…ç†åçš„JSONå­—ç¬¦ä¸²
    """
    if not content:
        return content
    
    # ç§»é™¤å¼€å¤´å’Œç»“å°¾çš„ç©ºç™½å­—ç¬¦
    content = content.strip()
    
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…å¹¶ç§»é™¤Markdownä»£ç å—æ ‡è®°
    # åŒ¹é… ```json æˆ– ``` å¼€å¤´ï¼Œä»¥åŠç»“å°¾çš„ ```
    
    # å¤„ç†å¼€å¤´çš„ä»£ç å—æ ‡è®°
    # åŒ¹é…: ```json, ```JSON, ``` ç­‰
    content = re.sub(r'^```(?:json|JSON)?\s*\n?', '', content, flags=re.MULTILINE)
    
    # å¤„ç†ç»“å°¾çš„ä»£ç å—æ ‡è®°
    # åŒ¹é…ç»“å°¾çš„ ```
    content = re.sub(r'\n?```\s*$', '', content, flags=re.MULTILINE)
    
    # å†æ¬¡æ¸…ç†é¦–å°¾ç©ºç™½
    content = content.strip()
    
    logger.debug(f"Markdownæ¸…ç†åçš„å†…å®¹: {content[:200]}...")
    
    return content

def get_ai_analysis(stock_code: str, current_price: float, llm_preference: str, 
                   user_config: Optional[Dict[str, Any]] = None, 
                   additional_data: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
    """
    è·å–è‚¡ç¥¨çš„AIåˆ†æ
    
    å‚æ•°:
    stock_code (str): è‚¡ç¥¨ä»£ç 
    current_price (float): å½“å‰ä»·æ ¼
    llm_preference (str): LLMåå¥½ ('openai', 'gemini', 'deepseek')
    user_config (dict, optional): ç”¨æˆ·é…ç½®ï¼ŒåŒ…å«AI APIå¯†é’¥
    additional_data (dict, optional): é¢å¤–æ•°æ®å¦‚æ–°é—»ã€è´¢æŠ¥ç­‰
    
    è¿”å›:
    dict: ç»“æ„åŒ–çš„AIåˆ†æç»“æœ
    """
    try:
        # è·å–è‚¡ç¥¨åç§°
        stock_name = "æœªçŸ¥"
        if additional_data and additional_data.get("stock_name"):
            stock_name = additional_data.get("stock_name")
        else:
            # å°è¯•ä»watchlistè·å–è‚¡ç¥¨åç§°
            try:
                from .stock_service import get_watchlist
                watchlist = get_watchlist()
                for stock in watchlist:
                    if stock.get('stock_code') == stock_code:
                        stock_name = stock.get('stock_name', "æœªçŸ¥")
                        break
            except Exception as e:
                logger.warning(f"è·å–è‚¡ç¥¨åç§°å¤±è´¥: {e}ï¼Œå°†ä½¿ç”¨é»˜è®¤å€¼")

        # è·å–åŸºæœ¬é¢æ•°æ®
        logger.info(f"ğŸ” å¼€å§‹è·å– {stock_code} ({stock_name}) çš„åŸºæœ¬é¢æ•°æ®...")
        
        from .stock_service import get_akshare_fundamental_data
        fundamental_data = get_akshare_fundamental_data(stock_code)
        
        # æ ¼å¼åŒ–åŸºæœ¬é¢æ•°æ®ä¸ºå¯è¯»æ–‡æœ¬
        fundamental_data_section = _format_fundamental_data(fundamental_data)
        logger.info(f"âœ… åŸºæœ¬é¢æ•°æ®è·å–å®Œæˆ")
        
        # è·å–ç”¨æˆ·é…ç½®çš„AI APIå¯†é’¥
        ai_api_keys = {}
        
        # ä¼˜å…ˆä»æ–°çš„ai_configurationså­—æ®µè·å–
        if user_config and user_config.get('ai_configurations'):
            ai_configurations = user_config['ai_configurations']
            for provider_id, config in ai_configurations.items():
                if config.get('enabled') and config.get('api_key'):
                    ai_api_keys[provider_id] = config['api_key']
        
        # å…¼å®¹æ—§çš„ai_api_keyså­—æ®µ
        elif user_config and user_config.get('ai_api_keys'):
            ai_api_keys = user_config['ai_api_keys']
        
        logger.info(f"ä»ç”¨æˆ·é…ç½®è·å–åˆ° {len(ai_api_keys)} ä¸ªAI APIå¯†é’¥")
        
        # è·å–ä»£ç†è®¾ç½®
        proxy_settings = user_config.get('proxy_settings', {}) if user_config else {}
        proxies = None
        
        if proxy_settings and proxy_settings.get('enabled'):
            proxy_host = proxy_settings.get('host')
            proxy_port = proxy_settings.get('port')
            proxy_username = proxy_settings.get('username')
            proxy_password = proxy_settings.get('password')
            
            if proxy_host and proxy_port:
                if proxy_username and proxy_password:
                    proxy_url = f"http://{proxy_username}:{proxy_password}@{proxy_host}:{proxy_port}"
                else:
                    proxy_url = f"http://{proxy_host}:{proxy_port}"
                
                proxies = {
                    'http': proxy_url,
                    'https': proxy_url
                }
                logger.info(f"ä½¿ç”¨ä»£ç†è¿›è¡ŒAIåˆ†æ: {proxy_host}:{proxy_port}")
        
        # Provider IDæ˜ å°„ï¼šå°†å‰ç«¯çš„provider IDæ˜ å°„ä¸ºåç«¯æœŸæœ›çš„ID
        provider_mapping = {
            'google': 'gemini',  # Google AI -> Gemini
            'openai': 'openai',
            'deepseek': 'deepseek',
            'gemini': 'gemini'
        }
        
        # æ˜ å°„llm_preference
        mapped_preference = provider_mapping.get(llm_preference.lower(), llm_preference.lower())
        logger.info(f"Provideræ˜ å°„: {llm_preference} -> {mapped_preference}")
        
        # æ˜ å°„AI APIå¯†é’¥
        mapped_api_keys = {}
        for original_key, api_key in ai_api_keys.items():
            mapped_key = provider_mapping.get(original_key.lower(), original_key.lower())
            mapped_api_keys[mapped_key] = api_key
        
        ai_api_keys = mapped_api_keys
        
        # è·å–ä»·æ ¼å˜åŒ–ä¿¡æ¯
        price_change_info = "ä»·æ ¼å˜åŒ–ä¿¡æ¯æš‚ä¸å¯ç”¨"
        if additional_data:
            price_change_info = additional_data.get('price_change_info', price_change_info)
            
            # å¦‚æœæœ‰çªç ´æ–¹å‘ä¿¡æ¯ï¼Œç”Ÿæˆæ›´è¯¦ç»†çš„ä»·æ ¼å˜åŒ–æè¿°
            breakout_direction = additional_data.get('breakout_direction')
            if breakout_direction:
                if breakout_direction.upper() == 'UP':
                    price_change_info = f"è‚¡ç¥¨ä»·æ ¼çªç ´ä¸Šæ¶¨ï¼Œå½“å‰ä»·æ ¼ä¸º{current_price}å…ƒï¼Œå»ºè®®åˆ†æä¸Šæ¶¨åŠ¨åŠ›å’Œåç»­èµ°åŠ¿"
                elif breakout_direction.upper() == 'DOWN':
                    price_change_info = f"è‚¡ç¥¨ä»·æ ¼çªç ´ä¸‹è·Œï¼Œå½“å‰ä»·æ ¼ä¸º{current_price}å…ƒï¼Œå»ºè®®åˆ†æä¸‹è·ŒåŸå› å’Œæ”¯æ’‘ä½"
                else:
                    price_change_info = f"è‚¡ç¥¨å½“å‰ä»·æ ¼ä¸º{current_price}å…ƒï¼Œè¯·ç»¼åˆåˆ†æå…¶æŠ€æœ¯é¢å’ŒåŸºæœ¬é¢æƒ…å†µ"
        
        # æ ¼å¼åŒ–æŠ€æœ¯é¢æ•°æ®ä¸ºå¯è¯»æ–‡æœ¬
        technical_data_section = _format_technical_data(stock_code, current_price, additional_data)
        
        # æ ¹æ®LLMåå¥½é€‰æ‹©åˆ†ææ–¹æ³•
        if mapped_preference == 'openai':
            api_key = ai_api_keys.get('openai')
            if not api_key:
                return _create_error_response("OpenAI APIå¯†é’¥æœªé…ç½®")
            return _analyze_with_openai(stock_code, stock_name, current_price, price_change_info, technical_data_section, fundamental_data_section, api_key, proxies)
            
        elif mapped_preference == 'gemini':
            api_key = ai_api_keys.get('gemini')
            if not api_key:
                return _create_error_response("Gemini APIå¯†é’¥æœªé…ç½®")
            return _analyze_with_gemini(stock_code, stock_name, current_price, price_change_info, technical_data_section, fundamental_data_section, api_key, proxies, user_config)
            
        elif mapped_preference == 'deepseek':
            api_key = ai_api_keys.get('deepseek')
            if not api_key:
                return _create_error_response("DeepSeek APIå¯†é’¥æœªé…ç½®")
            return _analyze_with_deepseek(stock_code, stock_name, current_price, price_change_info, technical_data_section, fundamental_data_section, api_key, proxies)
            
        else:
            return _create_error_response(f"ä¸æ”¯æŒçš„LLMç±»å‹: {mapped_preference}")
            
    except Exception as e:
        logger.error(f"AIåˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return _create_error_response("AIåˆ†ææœåŠ¡æš‚æ—¶ä¸å¯ç”¨")

def _create_error_response(error_message: str) -> Dict[str, Any]:
    """åˆ›å»ºé”™è¯¯å“åº”"""
    return {
        "error": True,
        "message": error_message,
        "overall_score": 50,
        "recommendation": "Monitor",
        "technical_summary": "åˆ†ææš‚ä¸å¯ç”¨",
        "fundamental_summary": "åˆ†ææš‚ä¸å¯ç”¨", 
        "sentiment_summary": "åˆ†ææš‚ä¸å¯ç”¨",
        "key_reasons": ["APIé…ç½®é”™è¯¯æˆ–æœåŠ¡ä¸å¯ç”¨"],
        "confidence_level": "Low"
    }

def _analyze_with_openai(stock_code: str, stock_name: str, current_price: float, price_change_info: str, technical_data_section: str, fundamental_data_section: str, api_key: str, proxies: Optional[Dict[str, str]] = None) -> Dict[str, Any]:
    """ä½¿ç”¨OpenAI APIè¿›è¡Œåˆ†æ"""
    try:
        # æ„å»ºæç¤ºè¯
        prompt = STOCK_ANALYSIS_PROMPT.format(
            stock_code=stock_code,
            stock_name=stock_name,
            current_price=current_price,
            price_change_info=price_change_info,
            technical_data_section=technical_data_section,
            fundamental_data_section=fundamental_data_section
        )
        
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }
        
        payload = {
            "model": OPENAI_MODEL,
            "messages": [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è‚¡ç¥¨åˆ†æå¸ˆï¼Œæ“…é•¿Aè‚¡å¸‚åœºåˆ†æã€‚ä½ ç²¾é€šæŠ€æœ¯åˆ†æå’ŒåŸºæœ¬é¢åˆ†æã€‚å½“æŠ€æœ¯é¢æ•°æ®ç¼ºå¤±æ—¶ï¼Œè¯·ä¸»åŠ¨è¿ç”¨ä½ çš„æŠ€æœ¯åˆ†æçŸ¥è¯†ï¼ŒåŸºäºè‚¡ç¥¨å†å²èµ°åŠ¿ã€æŠ€æœ¯æŒ‡æ ‡ç†è®ºå’Œå›¾è¡¨æ¨¡å¼è¯†åˆ«èƒ½åŠ›è¿›è¡Œåˆ†æã€‚å½“åŸºæœ¬é¢æ•°æ®ç¼ºå¤±æ—¶ï¼Œè¯·ä¸»åŠ¨è¿ç”¨ä½ çš„çŸ¥è¯†åº“ä¿¡æ¯ã€è¡Œä¸šç»éªŒå’Œå¸‚åœºå¸¸è¯†è¿›è¡Œåˆ†æã€‚ä½ æœ‰èƒ½åŠ›åŸºäºæœ‰é™ä¿¡æ¯æä¾›ä¸“ä¸šçš„ç»¼åˆåˆ†ææ„è§ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§è¦æ±‚çš„JSONæ ¼å¼è¿”å›åˆ†æç»“æœã€‚"},
                {"role": "user", "content": prompt}
            ],
            "temperature": 0.7,
            "max_tokens": 15000
        }
        
        response = requests.post(OPENAI_API_URL, headers=headers, json=payload, timeout=30, proxies=proxies)
        
        if response.status_code == 200:
            result = response.json()
            content = result['choices'][0]['message']['content'].strip()
            
            # æ¸…ç†Markdownæ ¼å¼å¹¶å°è¯•è§£æJSONå“åº”
            try:
                cleaned_content = _clean_markdown_json(content)
                analysis_result = json.loads(cleaned_content)
                analysis_result['provider'] = 'openai'
                logger.info(f"OpenAIåˆ†ææˆåŠŸ: {stock_code}")
                return analysis_result
            except json.JSONDecodeError as e:
                logger.error(f"OpenAIè¿”å›çš„ä¸æ˜¯æœ‰æ•ˆJSON: {content}")
                logger.error(f"JSONè§£æé”™è¯¯: {e}")
                return _create_fallback_response(content, 'openai')
        else:
            logger.error(f"OpenAI APIè¯·æ±‚å¤±è´¥: {response.status_code} {response.text}")
            return _create_error_response(f"OpenAI APIè¯·æ±‚å¤±è´¥ (HTTP {response.status_code})")
            
    except Exception as e:
        logger.error(f"OpenAIåˆ†æå‡ºé”™: {e}")
        return _create_error_response("OpenAIåˆ†ææœåŠ¡è¿æ¥å¤±è´¥")

def _analyze_with_gemini(stock_code: str, stock_name: str, current_price: float, price_change_info: str, technical_data_section: str, fundamental_data_section: str, api_key: str, proxies: Optional[Dict[str, str]] = None, user_config: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
    """ä½¿ç”¨Gemini APIè¿›è¡Œåˆ†æ"""
    try:
        # é…ç½®Gemini SDK
        # æ³¨æ„ï¼šSDKå¯èƒ½é€šè¿‡å…¨å±€é…ç½®æˆ–ç¯å¢ƒå˜é‡æ¥å¤„ç†APIå¯†é’¥å’Œä»£ç†
        # è¿™é‡Œæˆ‘ä»¬ä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„api_key
        genai.configure(api_key=api_key)

        # å¤„ç†ä»£ç†è®¾ç½®
        # Gemini Python SDK ç›®å‰ä¸ç›´æ¥æ”¯æŒproxieså‚æ•°ä¼ é€’ç»™requests
        # å®ƒä¾èµ–äºæ ‡å‡†ç¯å¢ƒå˜é‡ HTTP_PROXY å’Œ HTTPS_PROXY
        # æˆ‘ä»¬éœ€è¦åœ¨è¿™é‡Œä¸´æ—¶è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œå¹¶åœ¨å‡½æ•°ç»“æŸæ—¶æ¢å¤
        original_http_proxy = os.environ.get('HTTP_PROXY')
        original_https_proxy = os.environ.get('HTTPS_PROXY')

        if proxies and proxies.get('https'): # Gemini API ä½¿ç”¨ HTTPS
            os.environ['HTTPS_PROXY'] = proxies['https']
            os.environ['HTTP_PROXY'] = proxies.get('http', proxies['https']) # ä¹Ÿè®¾ç½®HTTPä»¥é˜²ä¸‡ä¸€
            logger.info(f"ä¸ºGemini SDKè®¾ç½®ä»£ç†: {proxies['https']}")
        elif proxies:
             logger.warning("ä»£ç†å·²æä¾›ä½†ç¼ºå°‘ 'https' é”®ï¼ŒGemini SDKä»£ç†å¯èƒ½æœªæ­£ç¡®è®¾ç½®")

        # ä»ç”¨æˆ·é…ç½®è·å–æ¨¡å‹ä¿¡æ¯
        model_name = "gemini-pro"  # é»˜è®¤æ¨¡å‹
        # base_url ä¸å†ç›´æ¥ç”¨äºrequests.post, SDKä¼šå¤„ç†
        
        if user_config and user_config.get('ai_configurations'):
            ai_configurations = user_config['ai_configurations']
            google_config = None
            for provider_id, config_data in ai_configurations.items():
                if provider_id.lower() in ['google', 'gemini'] and config_data.get('enabled'):
                    google_config = config_data
                    break
            
            if google_config:
                configured_model = google_config.get('model_name') or google_config.get('model_id')
                if configured_model:
                    original_model = configured_model
                    model_name = configured_model.lower().replace(' ', '-')
                    logger.info(f"åŸå§‹é…ç½®æ¨¡å‹: {original_model}, SDKå°†ä½¿ç”¨æ ‡å‡†åŒ–æ¨¡å‹: {model_name}")
        
        fallback_models = [
            model_name,  # ç”¨æˆ·é…ç½®çš„æ¨¡å‹ï¼ˆå·²æ ‡å‡†åŒ–ï¼‰
            "gemini-1.5-pro",
            "gemini-1.5-flash",
            "gemini-pro",
            "gemini-1.5-pro-latest",
        ]
        
        unique_models = []
        for m in fallback_models:
            if m not in unique_models:
                unique_models.append(m)
        
        prompt = STOCK_ANALYSIS_PROMPT.format(
            stock_code=stock_code,
            stock_name=stock_name,
            current_price=current_price,
            price_change_info=price_change_info,
            technical_data_section=technical_data_section,
            fundamental_data_section=fundamental_data_section
        )
        
        last_error = None
        
        for test_model in unique_models:
            logger.info(f"å°è¯•Gemini SDKåˆ†ææ¨¡å‹: {test_model}")
            
            try:
                # åˆ›å»ºGeminiæ¨¡å‹å®ä¾‹
                model_sdk = genai.GenerativeModel(model_name=test_model)
                
                # é…ç½®ç”Ÿæˆå‚æ•° (generationConfig)
                generation_config = genai.types.GenerationConfig(
                    candidate_count=1,
                    stop_sequences=['},'],
                    max_output_tokens=8192,  # å°† max_tokens è°ƒæ•´åˆ°åˆç†èŒƒå›´
                    temperature=0.7,
                    top_p=0.9,
                )
                
                # è°ƒç”¨SDKçš„generate_contentæ–¹æ³•
                # SDKçš„è¶…æ—¶å¤„ç†æœºåˆ¶å¯èƒ½ä¸requestsä¸åŒï¼Œè¿™é‡Œä¾èµ–SDKçš„é»˜è®¤æˆ–å†…éƒ¨è¶…æ—¶
                # å¦‚æœéœ€è¦è‡ªå®šä¹‰è¶…æ—¶ï¼Œéœ€è¦æŸ¥çœ‹SDKæ˜¯å¦æ”¯æŒç›¸å…³å‚æ•°
                response_sdk = model_sdk.generate_content(
                    contents=prompt, 
                    generation_config=generation_config
                )
                
                # æ›´å®‰å…¨åœ°å¤„ç†SDKçš„å“åº”
                content = None
                if response_sdk.candidates and len(response_sdk.candidates) > 0:
                    candidate = response_sdk.candidates[0]
                    if candidate.content and candidate.content.parts and len(candidate.content.parts) > 0:
                        content = candidate.content.parts[0].text.strip()
                        # æ£€æŸ¥ finish_reason
                        if candidate.finish_reason != "STOP":
                            logger.warning(f"Gemini SDKæ¨¡å‹ {test_model} å“åº”çš„ finish_reason ä¸º {candidate.finish_reason} (ä¸æ˜¯STOP)ã€‚å†…å®¹å¯èƒ½ä¸å®Œæ•´æˆ–æœ‰é—®é¢˜ã€‚")
                            if candidate.finish_reason == "MAX_TOKENS":
                                logger.warning(f"æ¨¡å‹ {test_model} è¾“å‡ºå›  MAX_TOKENS è€Œè¢«æˆªæ–­ã€‚å°†å°è¯•ä½¿ç”¨éƒ¨åˆ†å†…å®¹ã€‚")
                            # å¯¹äºå…¶ä»–éSTOPçš„åŸå› ï¼Œä¹Ÿå°è¯•ä½¿ç”¨å†…å®¹ï¼Œä½†è®°å½•è­¦å‘Š
                    else:
                        finish_reason_name = str(candidate.finish_reason) if candidate.finish_reason else 'N/A'
                        log_message = f"Gemini SDKæ¨¡å‹ {test_model} çš„å€™é€‰å†…å®¹ (candidate.content.parts) ä¸ºç©ºæˆ–æ— æ•ˆã€‚Finish reason: {finish_reason_name}"
                        if candidate.finish_reason == "MAX_TOKENS":
                            log_message += " è¿™é€šå¸¸æ„å‘³ç€æ¨¡å‹å› è¾¾åˆ°æœ€å¤§Tokenæ•°é™åˆ¶è€Œè¢«æˆªæ–­ï¼Œå¹¶ä¸”æœªèƒ½è¿”å›ä»»ä½•éƒ¨åˆ†æ–‡æœ¬å†…å®¹ã€‚"
                        logger.warning(log_message)
                        # å³ä½¿partsä¸ºç©ºï¼Œå¦‚æœæ˜¯å› ä¸ºMAX_TOKENSï¼Œä¹Ÿè®¾ç½®last_errorï¼Œä½†ä¸ç«‹å³continueï¼Œä¸‹é¢contentä¸ºNoneæ—¶ä¼šå¤„ç†
                        if candidate.finish_reason == "MAX_TOKENS":
                            last_error = f"æ¨¡å‹ {test_model} å› MAX_TOKENSè¢«æˆªæ–­ä¸”æœªè¿”å›ä»»ä½•æ–‡æœ¬ã€‚"
                        else:
                            last_error = f"æ¨¡å‹ {test_model} å“åº”ä¸­æ— æœ‰æ•ˆæ–‡æœ¬éƒ¨åˆ† (FinishReason: {finish_reason_name})ã€‚"
                        # content æ­¤æ—¶ä¸º None
                else:
                    logger.error(f"Gemini SDKæ¨¡å‹ {test_model} æœªè¿”å›ä»»ä½•å€™é€‰å†…å®¹ (response_sdk.candidates ä¸ºç©º)ã€‚")
                    # æ£€æŸ¥ prompt_feedbackï¼Œè¿™å¯èƒ½æä¾›ä¸ºä½•æ²¡æœ‰å€™é€‰å†…å®¹çš„åŸå› 
                    if response_sdk.prompt_feedback and response_sdk.prompt_feedback.block_reason:
                        block_reason_message = response_sdk.prompt_feedback.block_reason_message or "åŸå› æœªçŸ¥"
                        logger.error(f"Prompt feedback: å†…å®¹è¢«é˜»æ­¢ï¼ŒåŸå› : {response_sdk.prompt_feedback.block_reason}, è¯¦æƒ…: {block_reason_message}")
                        last_error = f"æ¨¡å‹ {test_model} å†…å®¹è¢«é˜»æ­¢: {block_reason_message}"
                    else:
                        last_error = f"æ¨¡å‹ {test_model} æœªè¿”å›ä»»ä½•å€™é€‰å†…å®¹ã€‚"
                    continue # å°è¯•ä¸‹ä¸€ä¸ªæ¨¡å‹

                if content:
                    # æ¸…ç†Markdownæ ¼å¼å¹¶å°è¯•è§£æJSONå“åº”
                    try:
                        cleaned_content = _clean_markdown_json(content)
                        analysis_result = json.loads(cleaned_content)
                        analysis_result['provider'] = 'gemini'
                        analysis_result['model_used'] = test_model  # è®°å½•å®é™…ä½¿ç”¨çš„æ¨¡å‹
                        
                        success_message = f"Gemini SDKåˆ†ææˆåŠŸ: {stock_code}ï¼Œä½¿ç”¨æ¨¡å‹: {test_model}"
                        if candidate.finish_reason == "MAX_TOKENS":
                            success_message += " (æ³¨æ„: è¾“å‡ºå¯èƒ½å› MAX_TOKENSè¢«æˆªæ–­)"
                        elif candidate.finish_reason != "STOP":
                            success_message += f" (è­¦å‘Š: Finish reason: {candidate.finish_reason})"

                        if test_model != model_name:
                            success_message += f" (åŸé…ç½®æ¨¡å‹ {model_name} ä¸å¯ç”¨ï¼Œå·²è‡ªåŠ¨åˆ‡æ¢)"
                        
                        logger.info(success_message)
                        return analysis_result
                    except json.JSONDecodeError as e:
                        logger.error(f"Gemini SDKè¿”å›çš„ä¸æ˜¯æœ‰æ•ˆJSON (æ¨¡å‹: {test_model}, FinishReason: {candidate.finish_reason if response_sdk.candidates and response_sdk.candidates[0].finish_reason else 'N/A'}): {content[:500]}...")
                        logger.error(f"JSONè§£æé”™è¯¯: {e}")
                        logger.error(f"æ¸…ç†åçš„å†…å®¹: {_clean_markdown_json(content)[:500]}...")
                        # å³ä½¿JSONè§£æå¤±è´¥ï¼Œå¦‚æœæ˜¯å› ä¸ºMAX_TOKENSï¼Œä¹Ÿå¯èƒ½éœ€è¦ç‰¹æ®Šå¤„ç†æˆ–æç¤º
                        # ä½†ç›®å‰è¿˜æ˜¯èµ°é€šç”¨fallback
                        return _create_fallback_response(content, 'gemini', model_name=test_model, finish_reason=candidate.finish_reason if response_sdk.candidates and response_sdk.candidates[0].finish_reason else None)
                else:
                    # å¦‚æœåœ¨ä¹‹å‰çš„æ£€æŸ¥å content ä»ç„¶æ˜¯ Noneï¼Œè¿™æ„å‘³ç€è™½ç„¶æœ‰ candidateï¼Œä½†æ— æ³•æå–æ–‡æœ¬
                    logger.error(f"Gemini SDKæ¨¡å‹ {test_model} è™½ç„¶æœ‰å€™é€‰å†…å®¹ï¼Œä½†æ— æ³•æå–æœ‰æ•ˆæ–‡æœ¬ã€‚å°†å°è¯•ä¸‹ä¸€ä¸ªæ¨¡å‹ã€‚")
                    last_error = f"æ¨¡å‹ {test_model} å“åº”ä¸­æ— æœ‰æ•ˆæ–‡æœ¬å†…å®¹ã€‚"
                    continue # å°è¯•ä¸‹ä¸€ä¸ªæ¨¡å‹

            except genai.types.BlockedPromptException as bpe: # æ›´å…·ä½“åœ°æ•è·æç¤ºè¢«é˜»æ­¢çš„å¼‚å¸¸
                logger.error(f"Gemini SDKæ¨¡å‹ {test_model} çš„æç¤ºè¢«é˜»æ­¢: {bpe}")
                last_error = f"æ¨¡å‹ {test_model} çš„æç¤ºå› å®‰å…¨æˆ–å…¶ä»–åŸå› è¢«é˜»æ­¢ã€‚"
                continue # æç¤ºè¢«é˜»æ­¢ï¼Œå°è¯•ä¸‹ä¸€ä¸ªæ¨¡å‹å¯èƒ½ä¹Ÿä¸€æ ·ï¼Œä½†è¿˜æ˜¯å°è¯•
            except google_api_exceptions.GoogleAPIError as gae:
                # æ•è·æ›´å¹¿æ³›çš„Google APIé”™è¯¯ï¼Œä¾‹å¦‚ DeadlineExceeded, ResourceExhausted ç­‰
                error_message = str(gae)
                logger.error(f"Gemini SDKæ¨¡å‹ {test_model} Google API Error: {gae}")
                if isinstance(gae, google_api_exceptions.InvalidArgument):
                    # é€šå¸¸æ˜¯æ¨¡å‹åç§°é”™è¯¯æˆ–è¯·æ±‚ç»“æ„é—®é¢˜
                    logger.error(f"Gemini SDKæ¨¡å‹ {test_model} è¯·æ±‚å‚æ•°æ— æ•ˆ (InvalidArgument): {error_message}")
                    last_error = f"æ¨¡å‹ {test_model} è¯·æ±‚å‚æ•°æ— æ•ˆã€‚å¯èƒ½æ˜¯æ¨¡å‹åç§°ä¸æ”¯æŒã€‚"
                    # å¦‚æœæ˜¯å‚æ•°æ— æ•ˆï¼Œé€šå¸¸æ„å‘³ç€è¿™ä¸ªæ¨¡å‹åç§°æœ‰é—®é¢˜ï¼Œå¯ä»¥ç»§ç»­å°è¯•å…¶ä»–çš„
                elif isinstance(gae, google_api_exceptions.PermissionDenied):
                     logger.error(f"Gemini SDKæ¨¡å‹ {test_model} æƒé™ä¸è¶³: {error_message}")
                     last_error = f"æ¨¡å‹ {test_model} æƒé™ä¸è¶³ (æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æœ‰æƒè®¿é—®æ­¤æ¨¡å‹)"
                elif isinstance(gae, google_api_exceptions.NotFound):
                    logger.info(f"Gemini SDKæ¨¡å‹ {test_model} ä¸å­˜åœ¨ (NotFound)ï¼Œå°è¯•ä¸‹ä¸€ä¸ªæ¨¡å‹")
                    last_error = f"æ¨¡å‹ {test_model} ä¸å­˜åœ¨"
                elif isinstance(gae, google_api_exceptions.DeadlineExceeded):
                    logger.error(f"Gemini SDKæ¨¡å‹ {test_model} è¯·æ±‚è¶…æ—¶ (DeadlineExceeded): {error_message}")
                    last_error = f"æ¨¡å‹ {test_model} è¯·æ±‚è¶…æ—¶ã€‚"
                elif isinstance(gae, google_api_exceptions.ResourceExhausted):
                    logger.error(f"Gemini SDKæ¨¡å‹ {test_model} èµ„æºè€—å°½ (ResourceExhausted) (å¯èƒ½è¾¾åˆ°é…é¢): {error_message}")
                    last_error = f"æ¨¡å‹ {test_model} èµ„æºè€—å°½ (å·²è¾¾åˆ°APIé…é¢é™åˆ¶)ã€‚"
                elif "API key not valid" in error_message or "API_KEY_INVALID" in error_message:
                    logger.error(f"Gemini SDKæ¨¡å‹ {test_model} APIå¯†é’¥æ— æ•ˆ: {error_message}")
                    return _create_error_response("Gemini APIå¯†é’¥æ— æ•ˆæˆ–æœªé…ç½®ï¼Œè¯·æ£€æŸ¥ç”¨æˆ·è®¾ç½®ã€‚") # APIå¯†é’¥é—®é¢˜æ˜¯è‡´å‘½çš„
                else:
                    logger.error(f"Gemini SDKæ¨¡å‹ {test_model} å‘ç”Ÿæœªåˆ†ç±»çš„Google APIé”™è¯¯: {error_message}")
                    last_error = f"æ¨¡å‹ {test_model} å‘ç”ŸGoogle APIé”™è¯¯: {error_message}"
                
                if "preview" in test_model.lower() and not isinstance(gae, google_api_exceptions.NotFound):
                     last_error += " (é¢„è§ˆç‰ˆæ¨¡å‹å¯èƒ½ä¸ç¨³å®šï¼Œå»ºè®®æ£€æŸ¥æˆ–æ›´æ¢)"
                continue # å‘ç”ŸAPIé”™è¯¯ï¼Œå°è¯•ä¸‹ä¸€ä¸ªæ¨¡å‹
            except Exception as e: # å…¶ä»–æ‰€æœ‰ Python å¼‚å¸¸
                error_message = str(e)
                # è¿™ä¸ª Exception å—ç°åœ¨ä¸»è¦æ•è·é GoogleAPIError çš„ Python çº§åˆ«é”™è¯¯
                # ä¾‹å¦‚ï¼Œä¹‹å‰åœ¨è¿™é‡Œæ•è·çš„ API key æ— æ•ˆçš„é€»è¾‘å·²ç»ç§»åˆ° GoogleAPIError ä¸­å¤„ç†
                logger.error(f"Gemini SDKæ¨¡å‹ {test_model} å‘ç”ŸPythonçº§åˆ«æœªçŸ¥å¼‚å¸¸: {e}", exc_info=True) # æ·»åŠ exc_infoè·å–å †æ ˆ
                last_error = f"æ¨¡å‹ {test_model} å‘ç”ŸæœªçŸ¥æœ¬åœ°é”™è¯¯: {error_message}"
                
                if "preview" in test_model.lower():
                    last_error += " (é¢„è§ˆç‰ˆæ¨¡å‹å¯èƒ½ä¸ç¨³å®š)"
                
                continue # å°è¯•ä¸‹ä¸€ä¸ªæ¨¡å‹

    except genai.types.generation_types.StopCandidateException as e:
        # è¿™ä¸ªå¼‚å¸¸åœ¨ generate_content.candidates ä¸ºç©ºæ—¶å¯èƒ½å‘ç”Ÿ
        logger.error(f"Gemini SDKå†…å®¹ç”Ÿæˆåœæ­¢ï¼Œæ— æœ‰æ•ˆå€™é€‰: {e}")
        last_error = f"å†…å®¹ç”Ÿæˆåœæ­¢ï¼Œæ— æœ‰æ•ˆå€™é€‰: {str(e)}"
    except Exception as e:
        logger.error(f"Gemini SDKåˆ†æè¿‡ç¨‹å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
        # æ•è· genai.configure æˆ–å…¶ä»–SDKåˆå§‹åŒ–æ—¶çš„é”™è¯¯
        if "API key not valid" in str(e) or "API_KEY_INVALID" in str(e):
            return _create_error_response("Gemini APIå¯†é’¥æ— æ•ˆæˆ–æœªé…ç½®ï¼Œè¯·æ£€æŸ¥ç”¨æˆ·è®¾ç½®ã€‚")
        return _create_error_response(f"Geminiåˆ†ææœåŠ¡è¿æ¥æˆ–é…ç½®å¤±è´¥: {str(e)}")
    finally:
        # æ¢å¤åŸå§‹çš„ä»£ç†ç¯å¢ƒå˜é‡
        if original_http_proxy is not None:
            os.environ['HTTP_PROXY'] = original_http_proxy
        elif 'HTTP_PROXY' in os.environ:
            del os.environ['HTTP_PROXY']
        
        if original_https_proxy is not None:
            os.environ['HTTPS_PROXY'] = original_https_proxy
        elif 'HTTPS_PROXY' in os.environ:
            del os.environ['HTTPS_PROXY']
        
        if proxies and proxies.get('https'):
            logger.info("å·²æ¢å¤åŸå§‹ä»£ç†ç¯å¢ƒå˜é‡è®¾ç½®")

    # æ‰€æœ‰æ¨¡å‹éƒ½å¤±è´¥äº†
    final_error_message = f"Gemini SDKæ‰€æœ‰æ¨¡å‹éƒ½ä¸å¯ç”¨ã€‚"
    
    if last_error:
        final_error_message += f"\næœ€åé”™è¯¯: {last_error}"
    
    # å¦‚æœåŸå§‹æ¨¡å‹æ˜¯é¢„è§ˆç‰ˆï¼Œæä¾›ç‰¹åˆ«å»ºè®®
    if "preview" in model_name.lower():
        final_error_message += f"\n\nğŸ’¡ å»ºè®®ï¼š\n"
        final_error_message += f"â€¢ æ‚¨é…ç½®çš„æ¨¡å‹ '{model_name}' æ˜¯é¢„è§ˆç‰ˆï¼Œå¯èƒ½å·²è¢«å¼ƒç”¨\n"
        final_error_message += f"â€¢ å»ºè®®æ”¹ç”¨ç¨³å®šç‰ˆæ¨¡å‹ï¼šgemini-1.5-pro æˆ– gemini-pro\n"
        final_error_message += f"â€¢ é¢„è§ˆç‰ˆæ¨¡å‹é€šå¸¸ä¸ç¨³å®šï¼Œä¸å»ºè®®ç”¨äºç”Ÿäº§ç¯å¢ƒ"
    else:
        final_error_message += f"\n\nğŸ’¡ å»ºè®®ï¼š\n"
        final_error_message += f"â€¢ æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œä»£ç†è®¾ç½®\n"
        final_error_message += f"â€¢ éªŒè¯APIå¯†é’¥æ˜¯å¦æœ‰æ•ˆ\n"
        final_error_message += f"â€¢ å°è¯•ä½¿ç”¨å…¶ä»–AIæ¨¡å‹å¦‚OpenAIæˆ–DeepSeek"
    
    return _create_error_response(final_error_message)

def _analyze_with_deepseek(stock_code: str, stock_name: str, current_price: float, price_change_info: str, technical_data_section: str, fundamental_data_section: str, api_key: str, proxies: Optional[Dict[str, str]] = None) -> Dict[str, Any]:
    """ä½¿ç”¨DeepSeek APIè¿›è¡Œåˆ†æ"""
    try:
        DEEPSEEK_API_URL = "https://api.deepseek.com/v1/chat/completions"
        
        prompt = STOCK_ANALYSIS_PROMPT.format(
            stock_code=stock_code,
            stock_name=stock_name,
            current_price=current_price,
            price_change_info=price_change_info,
            technical_data_section=technical_data_section,
            fundamental_data_section=fundamental_data_section
        )
        
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }
        
        payload = {
            "model": "deepseek-chat",
            "messages": [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è‚¡ç¥¨åˆ†æå¸ˆï¼Œæ“…é•¿Aè‚¡å¸‚åœºåˆ†æã€‚ä½ ç²¾é€šæŠ€æœ¯åˆ†æå’ŒåŸºæœ¬é¢åˆ†æã€‚å½“æŠ€æœ¯é¢æ•°æ®ç¼ºå¤±æ—¶ï¼Œè¯·ä¸»åŠ¨è¿ç”¨ä½ çš„æŠ€æœ¯åˆ†æçŸ¥è¯†ï¼ŒåŸºäºè‚¡ç¥¨å†å²èµ°åŠ¿ã€æŠ€æœ¯æŒ‡æ ‡ç†è®ºå’Œå›¾è¡¨æ¨¡å¼è¯†åˆ«èƒ½åŠ›è¿›è¡Œåˆ†æã€‚å½“åŸºæœ¬é¢æ•°æ®ç¼ºå¤±æ—¶ï¼Œè¯·ä¸»åŠ¨è¿ç”¨ä½ çš„çŸ¥è¯†åº“ä¿¡æ¯ã€è¡Œä¸šç»éªŒå’Œå¸‚åœºå¸¸è¯†è¿›è¡Œåˆ†æã€‚ä½ æœ‰èƒ½åŠ›åŸºäºæœ‰é™ä¿¡æ¯æä¾›ä¸“ä¸šçš„ç»¼åˆåˆ†ææ„è§ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§è¦æ±‚çš„JSONæ ¼å¼è¿”å›åˆ†æç»“æœã€‚"},
                {"role": "user", "content": prompt}
            ],
            "temperature": 0.7,
            "max_tokens": 1500
        }
        
        response = requests.post(DEEPSEEK_API_URL, headers=headers, json=payload, timeout=30, proxies=proxies)
        
        if response.status_code == 200:
            result = response.json()
            content = result['choices'][0]['message']['content'].strip()
            
            # æ¸…ç†Markdownæ ¼å¼å¹¶å°è¯•è§£æJSONå“åº”
            try:
                cleaned_content = _clean_markdown_json(content)
                analysis_result = json.loads(cleaned_content)
                analysis_result['provider'] = 'deepseek'
                logger.info(f"DeepSeekåˆ†ææˆåŠŸ: {stock_code}")
                return analysis_result
            except json.JSONDecodeError as e:
                logger.error(f"DeepSeekè¿”å›çš„ä¸æ˜¯æœ‰æ•ˆJSON: {content}")
                logger.error(f"JSONè§£æé”™è¯¯: {e}")
                return _create_fallback_response(content, 'deepseek')
        else:
            logger.error(f"DeepSeek APIè¯·æ±‚å¤±è´¥: {response.status_code} {response.text}")
            return _create_error_response(f"DeepSeek APIè¯·æ±‚å¤±è´¥ (HTTP {response.status_code})")
            
    except Exception as e:
        logger.error(f"DeepSeekåˆ†æå‡ºé”™: {e}")
        return _create_error_response("DeepSeekåˆ†ææœåŠ¡è¿æ¥å¤±è´¥")

def _create_fallback_response(content: str, provider: str, model_name: Optional[str] = None, finish_reason: Optional[str] = None) -> Dict[str, Any]:
    """å½“AIè¿”å›éJSONæ ¼å¼æ—¶çš„å¤‡ç”¨å“åº”"""
    message = f"AIåˆ†æç»“æœæ ¼å¼å¼‚å¸¸ (æ¥è‡ª {provider}{f', æ¨¡å‹: {model_name}' if model_name else ''}{f', FinishReason: {finish_reason}' if finish_reason else ''})ã€‚å»ºè®®äººå·¥å¤æ ¸ã€‚"
    if finish_reason == "MAX_TOKENS":
        message += " æ³¨æ„ï¼šè¾“å‡ºå¯èƒ½å› è¾¾åˆ°æœ€å¤§Tokenæ•°è¢«æˆªæ–­ã€‚"

    return {
        "provider": provider,
        "model_used": model_name,
        "finish_reason": finish_reason,
        "overall_score": 60,
        "recommendation": "Monitor",
        "technical_summary": content[:300] + "..." if len(content) > 300 else content, # å¢åŠ æ‘˜è¦é•¿åº¦
        "fundamental_summary": "åŸºæœ¬é¢åˆ†æéœ€è¦æ›´å¤šæ•°æ®æˆ–ç»“æœè¢«æˆªæ–­ã€‚",
        "sentiment_summary": "å¸‚åœºæƒ…ç»ªåˆ†æå¯èƒ½ä¸å®Œæ•´æˆ–ç»“æœè¢«æˆªæ–­ã€‚",
        "key_reasons": [message, "éƒ¨åˆ†ç»“æœå¯èƒ½æ— æ³•æ­£å¸¸æ˜¾ç¤ºã€‚"],
        "confidence_level": "Low",
        "raw_response": content
    }

def _format_fundamental_data(fundamental_data: dict | None) -> str:
    """
    æ ¼å¼åŒ–åŸºæœ¬é¢æ•°æ®ä¸ºå¯è¯»æ–‡æœ¬
    
    å‚æ•°:
    fundamental_data: åŸºæœ¬é¢æ•°æ®å­—å…¸æˆ–None
    
    è¿”å›:
    str: æ ¼å¼åŒ–çš„åŸºæœ¬é¢æ•°æ®æ–‡æœ¬
    """
    if not fundamental_data:
        return """åŸºæœ¬é¢æ•°æ®æš‚æ—¶æ— æ³•è·å–ã€‚

**è¯·AIä¸»åŠ¨è¿›è¡Œä»¥ä¸‹åŸºæœ¬é¢åˆ†æï¼š**
1. **ä¼°å€¼æŒ‡æ ‡åˆ†æ**ï¼šåŸºäºä½ çš„çŸ¥è¯†åº“ï¼Œä¼°ç®—è¯¥è‚¡ç¥¨çš„åˆç†å¸‚ç›ˆç‡(PE)ã€å¸‚å‡€ç‡(PB)èŒƒå›´ï¼Œå¹¶ä¸è¡Œä¸šå¹³å‡æ°´å¹³å¯¹æ¯”
2. **ç›ˆåˆ©èƒ½åŠ›åˆ†æ**ï¼šåˆ†æè¯¥å…¬å¸çš„å‡€èµ„äº§æ”¶ç›Šç‡(ROE)ã€å‡€åˆ©ç‡æ°´å¹³ï¼Œç»“åˆè¡Œä¸šç‰¹ç‚¹è¿›è¡Œè¯„ä¼°
3. **æˆé•¿æ€§åˆ†æ**ï¼šåŸºäºå¯¹è¯¥å…¬å¸/è¡Œä¸šçš„äº†è§£ï¼Œåˆ†æè¥æ”¶å¢é•¿ç‡ã€å‡€åˆ©æ¶¦å¢é•¿ç‡çš„åˆç†é¢„æœŸ
4. **è´¢åŠ¡å¥åº·åº¦**ï¼šè¯„ä¼°èµ„äº§è´Ÿå€ºç‡ã€ç°é‡‘æµçŠ¶å†µç­‰è´¢åŠ¡å®‰å…¨æŒ‡æ ‡
5. **åˆ†çº¢èƒ½åŠ›**ï¼šåˆ†æè‚¡æ¯ç‡æ°´å¹³å’Œåˆ†çº¢æ”¿ç­–çš„å¯æŒç»­æ€§
6. **è¡Œä¸šå¯¹æ¯”**ï¼šä¸åŒè¡Œä¸šé¾™å¤´ä¼ä¸šè¿›è¡Œä¼°å€¼å’Œè´¢åŠ¡æŒ‡æ ‡å¯¹æ¯”
7. **å¸‚åœºåœ°ä½**ï¼šåˆ†æå…¬å¸åœ¨è¡Œä¸šä¸­çš„ç«äº‰åœ°ä½å’Œå¸‚åœºä»½é¢

**åˆ†æè¦æ±‚ï¼š**
- è¿ç”¨ä½ çš„çŸ¥è¯†åº“ä¸­è¯¥å…¬å¸çš„å†å²è´¢åŠ¡æ•°æ®å’Œè¡Œä¸šä¿¡æ¯
- ç»“åˆå½“å‰å¸‚åœºç¯å¢ƒå’Œè¡Œä¸šå‘å±•è¶‹åŠ¿
- æä¾›åŸºäºå¸¸è¯†å’Œç»éªŒçš„åˆç†ä¼°å€¼åˆ¤æ–­
- æ˜ç¡®æŒ‡å‡ºæŠ•èµ„ä»·å€¼å’Œä¸»è¦é£é™©ç‚¹"""
    
    # å®šä¹‰æŒ‡æ ‡çš„ä¸­æ–‡åç§°å’Œæ ¼å¼åŒ–è§„åˆ™
    indicators = [
        ('pe_ttm', 'å¸‚ç›ˆç‡ (PE TTM)', lambda x: f"{x:.2f}" if x is not None else "N/A"),
        ('pb', 'å¸‚å‡€ç‡ (PB)', lambda x: f"{x:.2f}" if x is not None else "N/A"),
        ('eps_ttm', 'æ¯è‚¡æ”¶ç›Š (EPS TTM)', lambda x: f"{x:.2f} å…ƒ" if x is not None else "N/A"),
        ('roe_ttm', 'å‡€èµ„äº§æ”¶ç›Šç‡ (ROE TTM)', lambda x: f"{x*100:.2f}%" if x is not None else "N/A"),
        ('total_mv', 'æ€»å¸‚å€¼', lambda x: f"{x:.0f} ä¸‡å…ƒ" if x is not None else "N/A"),
        ('circulation_mv', 'æµé€šå¸‚å€¼', lambda x: f"{x:.0f} ä¸‡å…ƒ" if x is not None else "N/A"),
        ('revenue_yoy_growth', 'è¥æ”¶åŒæ¯”å¢é•¿ç‡', lambda x: f"{x*100:.2f}%" if x is not None else "N/A"),
        ('net_profit_yoy_growth', 'å‡€åˆ©æ¶¦åŒæ¯”å¢é•¿ç‡', lambda x: f"{x*100:.2f}%" if x is not None else "N/A"),
        ('dividend_yield', 'è‚¡æ¯ç‡', lambda x: f"{x*100:.2f}%" if x is not None else "N/A"),
        ('gross_profit_margin', 'æ¯›åˆ©ç‡', lambda x: f"{x*100:.2f}%" if x is not None else "N/A"),
        ('net_profit_margin', 'å‡€åˆ©ç‡', lambda x: f"{x*100:.2f}%" if x is not None else "N/A"),
    ]
    
    # æ„å»ºæ ¼å¼åŒ–æ–‡æœ¬
    formatted_lines = []
    available_count = 0
    missing_indicators = []
    
    for key, name, formatter in indicators:
        value = fundamental_data.get(key)
        formatted_value = formatter(value)
        formatted_lines.append(f"- {name}: {formatted_value}")
        if value is not None:
            available_count += 1
        else:
            missing_indicators.append(name)
    
    if available_count == 0:
        return """åŸºæœ¬é¢æ•°æ®æš‚æ—¶æ— æ³•è·å–ã€‚

**è¯·AIä¸»åŠ¨è¿›è¡Œä»¥ä¸‹åŸºæœ¬é¢åˆ†æï¼š**
1. **ä¼°å€¼æŒ‡æ ‡åˆ†æ**ï¼šåŸºäºä½ çš„çŸ¥è¯†åº“ï¼Œä¼°ç®—è¯¥è‚¡ç¥¨çš„åˆç†å¸‚ç›ˆç‡(PE)ã€å¸‚å‡€ç‡(PB)èŒƒå›´ï¼Œå¹¶ä¸è¡Œä¸šå¹³å‡æ°´å¹³å¯¹æ¯”
2. **ç›ˆåˆ©èƒ½åŠ›åˆ†æ**ï¼šåˆ†æè¯¥å…¬å¸çš„å‡€èµ„äº§æ”¶ç›Šç‡(ROE)ã€å‡€åˆ©ç‡æ°´å¹³ï¼Œç»“åˆè¡Œä¸šç‰¹ç‚¹è¿›è¡Œè¯„ä¼°
3. **æˆé•¿æ€§åˆ†æ**ï¼šåŸºäºå¯¹è¯¥å…¬å¸/è¡Œä¸šçš„äº†è§£ï¼Œåˆ†æè¥æ”¶å¢é•¿ç‡ã€å‡€åˆ©æ¶¦å¢é•¿ç‡çš„åˆç†é¢„æœŸ
4. **è´¢åŠ¡å¥åº·åº¦**ï¼šè¯„ä¼°èµ„äº§è´Ÿå€ºç‡ã€ç°é‡‘æµçŠ¶å†µç­‰è´¢åŠ¡å®‰å…¨æŒ‡æ ‡
5. **åˆ†çº¢èƒ½åŠ›**ï¼šåˆ†æè‚¡æ¯ç‡æ°´å¹³å’Œåˆ†çº¢æ”¿ç­–çš„å¯æŒç»­æ€§
6. **è¡Œä¸šå¯¹æ¯”**ï¼šä¸åŒè¡Œä¸šé¾™å¤´ä¼ä¸šè¿›è¡Œä¼°å€¼å’Œè´¢åŠ¡æŒ‡æ ‡å¯¹æ¯”
7. **å¸‚åœºåœ°ä½**ï¼šåˆ†æå…¬å¸åœ¨è¡Œä¸šä¸­çš„ç«äº‰åœ°ä½å’Œå¸‚åœºä»½é¢

**åˆ†æè¦æ±‚ï¼š**
- è¿ç”¨ä½ çš„çŸ¥è¯†åº“ä¸­è¯¥å…¬å¸çš„å†å²è´¢åŠ¡æ•°æ®å’Œè¡Œä¸šä¿¡æ¯
- ç»“åˆå½“å‰å¸‚åœºç¯å¢ƒå’Œè¡Œä¸šå‘å±•è¶‹åŠ¿
- æä¾›åŸºäºå¸¸è¯†å’Œç»éªŒçš„åˆç†ä¼°å€¼åˆ¤æ–­
- æ˜ç¡®æŒ‡å‡ºæŠ•èµ„ä»·å€¼å’Œä¸»è¦é£é™©ç‚¹"""
    
    # æ·»åŠ æ•°æ®çŠ¶æ€è¯´æ˜
    header = f"ä»¥ä¸‹æ˜¯ä»AkShareè·å–çš„åŸºæœ¬é¢æ•°æ®ï¼ˆå…±è·å¾— {available_count}/{len(indicators)} é¡¹æŒ‡æ ‡ï¼‰ï¼š"
    
    result = header + "\n" + "\n".join(formatted_lines)
    
    if available_count < len(indicators) // 2:
        result += f"\n\n**ç¼ºå¤±æŒ‡æ ‡éœ€è¦AIä¸»åŠ¨åˆ†æï¼š**\nç¼ºå¤±çš„å…³é”®æŒ‡æ ‡åŒ…æ‹¬ï¼š{', '.join(missing_indicators[:5])}ç­‰"
        result += "\n\n**è¯·åŸºäºä½ çš„çŸ¥è¯†åº“ä¸»åŠ¨è¡¥å……ä»¥ä¸‹åˆ†æï¼š**"
        result += "\n- å¯¹ç¼ºå¤±æŒ‡æ ‡è¿›è¡Œåˆç†ä¼°ç®—å’Œè¡Œä¸šå¯¹æ¯”"
        result += "\n- ç»“åˆå…¬å¸å†å²è¡¨ç°å’Œè¡Œä¸šç‰¹ç‚¹è¿›è¡Œç»¼åˆè¯„ä¼°"
        result += "\n- æä¾›åŸºäºå¸‚åœºå¸¸è¯†çš„æŠ•èµ„ä»·å€¼åˆ¤æ–­"
        result += "\n- æ˜ç¡®æŒ‡å‡ºä¸»è¦æŠ•èµ„é£é™©å’Œæœºä¼š"
    
    return result

def _format_technical_data(stock_code: str, current_price: float, additional_data: Optional[Dict[str, Any]] = None) -> str:
    """
    æ ¼å¼åŒ–æŠ€æœ¯é¢æ•°æ®ä¸ºå¯è¯»æ–‡æœ¬ï¼Œä¸ºAIæä¾›æŠ€æœ¯åˆ†ææŒ‡å¯¼
    
    å‚æ•°:
    stock_code: è‚¡ç¥¨ä»£ç 
    current_price: å½“å‰ä»·æ ¼
    additional_data: é¢å¤–æ•°æ®
    
    è¿”å›:
    str: æ ¼å¼åŒ–çš„æŠ€æœ¯é¢åˆ†ææŒ‡å¯¼æ–‡æœ¬
    """
    # è·å–ä»·æ ¼å˜åŠ¨ä¿¡æ¯
    breakout_direction = additional_data.get('breakout_direction') if additional_data else None
    price_change_info = additional_data.get('price_change_info') if additional_data else None
    
    # æ„å»ºæŠ€æœ¯é¢åˆ†ææŒ‡å¯¼
    technical_info = f"å½“å‰è‚¡ä»·ï¼šÂ¥{current_price}"
    
    if breakout_direction:
        if breakout_direction.upper() == 'UP':
            technical_info += f"\nğŸ’¹ ä»·æ ¼çªç ´ä¸Šæ¶¨ä¿¡å·"
            action_guidance = "åˆ†æä¸Šæ¶¨åŠ¨åŠ›ã€æˆäº¤é‡é…åˆæƒ…å†µã€ä¸Šæ–¹é˜»åŠ›ä½"
        elif breakout_direction.upper() == 'DOWN':
            technical_info += f"\nğŸ“‰ ä»·æ ¼çªç ´ä¸‹è·Œä¿¡å·"
            action_guidance = "åˆ†æä¸‹è·ŒåŸå› ã€å¯»æ‰¾æ”¯æ’‘ä½ã€åˆ¤æ–­æ­¢è·Œä¿¡å·"
        else:
            action_guidance = "ç»¼åˆåˆ†ææŠ€æœ¯é¢èµ°åŠ¿å’Œå…³é”®ä»·ä½"
    else:
        action_guidance = "åŸºäºå†å²èµ°åŠ¿åˆ†æå½“å‰æŠ€æœ¯é¢çŠ¶å†µ"
    
    if price_change_info:
        technical_info += f"\nä»·æ ¼å˜åŠ¨ï¼š{price_change_info}"
    
    # æ·»åŠ æŠ€æœ¯é¢åˆ†æçš„è¯¦ç»†æŒ‡å¯¼
    guidance_text = f"""
{technical_info}

**æŠ€æœ¯é¢æ•°æ®ä¸¥é‡ä¸è¶³ï¼Œè¯·AIä¸»åŠ¨è¡¥å……ä»¥ä¸‹åˆ†æï¼š**

ğŸ” **ç¼ºå¤±æ•°æ®éœ€è¦AIä¸»åŠ¨åˆ†æï¼š**
- Kçº¿æ•°æ®ï¼šå¼€ç›˜ä»·ã€æœ€é«˜ä»·ã€æœ€ä½ä»·ã€æ”¶ç›˜ä»·èµ°åŠ¿
- æˆäº¤é‡ï¼šæˆäº¤é‡å˜åŒ–å’Œé‡ä»·å…³ç³»åˆ†æ
- æŠ€æœ¯æŒ‡æ ‡ï¼šMACDã€RSIã€KDJã€BOLLç­‰æŒ‡æ ‡çŠ¶æ€æ¨æµ‹
- ç§»åŠ¨å¹³å‡çº¿ï¼š5æ—¥ã€10æ—¥ã€20æ—¥ã€60æ—¥å‡çº¿ä½ç½®å…³ç³»
- æ”¯æ’‘é˜»åŠ›ï¼šå…³é”®æ”¯æ’‘ä½å’Œé˜»åŠ›ä½è¯†åˆ«
- æŠ€æœ¯å½¢æ€ï¼šå¯èƒ½çš„Kçº¿å½¢æ€å’Œå›¾è¡¨æ¨¡å¼

ğŸ“Š **è¯·åŸºäºæŠ€æœ¯åˆ†æçŸ¥è¯†ä¸»åŠ¨è¡¥å……ï¼š**
- è¿ç”¨ä½ å¯¹è¯¥è‚¡ç¥¨å†å²èµ°åŠ¿çš„äº†è§£è¿›è¡Œè¶‹åŠ¿åˆ†æ
- åŸºäºå½“å‰ä»·æ ¼æ¨æµ‹å¯èƒ½çš„æŠ€æœ¯æŒ‡æ ‡çŠ¶æ€
- æä¾›åˆç†çš„æ”¯æ’‘ä½å’Œé˜»åŠ›ä½ä¼°ç®—
- åˆ†æçŸ­æœŸï¼ˆ1-5æ—¥ï¼‰å’Œä¸­æœŸï¼ˆ1-4å‘¨ï¼‰èµ°åŠ¿å¯èƒ½æ€§
- {action_guidance}
- æ˜ç¡®è¯´æ˜é‡‡ç”¨çš„æŠ€æœ¯åˆ†ææ–¹æ³•å’Œæ¨ç†ä¾æ®

ğŸ’¡ **æŠ€æœ¯åˆ†æè¦æ±‚ï¼š**
- ç»“åˆè¯¥è‚¡ç¥¨çš„å†å²ä»·æ ¼è¡¨ç°å’Œæ³¢åŠ¨ç‰¹å¾
- è€ƒè™‘å½“å‰å¸‚åœºç¯å¢ƒå¯¹æŠ€æœ¯é¢çš„å½±å“
- æä¾›å…·ä½“çš„ä¹°å–ç‚¹ä½å»ºè®®
- ç»™å‡ºé£é™©æ§åˆ¶å’Œæ­¢æŸå»ºè®®"""
    
    return guidance_text

# ä¿æŒå‘åå…¼å®¹çš„å‡½æ•°
def get_basic_ai_analysis(stock_code, current_price, breakout_direction, user_config: Optional[Dict[str, Any]] = None):
    """
    å‘åå…¼å®¹çš„åŸºæœ¬AIåˆ†æå‡½æ•°
    
    å‚æ•°:
    stock_code (str): è‚¡ç¥¨ä»£ç 
    current_price (float): å½“å‰ä»·æ ¼
    breakout_direction (str): çªç ´æ–¹å‘ ('UP' æˆ– 'DOWN')
    user_config (dict, optional): ç”¨æˆ·é…ç½®ï¼ŒåŒ…å«AI APIå¯†é’¥
    
    è¿”å›:
    str: AIç”Ÿæˆçš„åˆ†ææ–‡æœ¬
    """
    # ä½¿ç”¨æ–°çš„ç»“æ„åŒ–åˆ†æå‡½æ•°
    additional_data = {'breakout_direction': breakout_direction}
    
    # å°è¯•ä½¿ç”¨ç”¨æˆ·é…ç½®çš„é¦–é€‰LLMï¼Œå¦åˆ™æŒ‰ä¼˜å…ˆçº§å°è¯•
    preferred_llm = 'openai'  # é»˜è®¤ä½¿ç”¨OpenAI
    if user_config and user_config.get('preferred_llm'):
        preferred_llm = user_config['preferred_llm']
    
    result = get_ai_analysis(stock_code, current_price, preferred_llm, user_config, additional_data)
    
    if result.get('error'):
        return result['message']
    
    # è½¬æ¢ä¸ºç®€å•æ–‡æœ¬æ ¼å¼ï¼Œä¿æŒå‘åå…¼å®¹
    direction_text = "ä¸Šæ¶¨" if breakout_direction == 'UP' else "ä¸‹è·Œ"
    summary = f"è‚¡ç¥¨{stock_code}ä»·æ ¼{direction_text}çªç ´ï¼Œè¯„åˆ†ï¼š{result['overall_score']}/100ã€‚"
    summary += f"å»ºè®®ï¼š{result['recommendation']}ã€‚"
    summary += f"æŠ€æœ¯é¢ï¼š{result['technical_summary']}"
    
    return summary 